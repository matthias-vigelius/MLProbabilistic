{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "Inferring the probability $p$ that a coin comes up with heads.\n",
    "\n",
    "Hypothesis $h_p$ is that the probability is $p \\in [0,1]$.\n",
    "\n",
    "In discrete case, we have \n",
    "\n",
    "$$\n",
    "P(\\mathcal{D}|h) = \\left[\\frac{1}{|h|}\\right]^{|\\mathcal{D}|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample probability:\n",
    "\n",
    "$$\n",
    "P(N|h_p) = {N \\choose k} p^k (1-p)^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prior: $h_p$ is uniformly distributed\n",
    "\n",
    "$$\n",
    "f_p(x) = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior:\n",
    "\n",
    "$$\n",
    "P(h_p|\\mathcal{D}) = \\frac{P(\\mathcal{D}|h_p) f_p}{\\int P(\\mathcal{D}|h_p) f_p\\ \\mathrm{d}x'}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.15**\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{a}{a+b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{ab}{(a+b)^2 (a+b+1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, mu, sigma = sympy.symbols(\"a b mu sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "amub = sympy.solve(mu - a/(a+b), a)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqn1 = sigma**2 - a*b/((a+b)**2*(a+b+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqn2 = sympy.simplify(eqn1.subs(a, amub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "solb = sympy.solve(eqn2, b, domain=sympy.S.Reals)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sola = ((b * mu)/(1-mu)).subs(b, solb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.975$"
      ],
      "text/plain": [
       "2.97500000000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sola.subs(mu, 0.7).subs(sigma, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.275$"
      ],
      "text/plain": [
       "1.27500000000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solb.subs(mu, 0.7).subs(sigma, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Future number of heads**\n",
    "Given the posterior distribution $\\theta \\sim \\mathrm{Beta}(a,b)$ what is the probability to have $x$ heads in $M$ trials?\n",
    "\n",
    "From conjugate prior relationship we know\n",
    "\n",
    "$$\n",
    "\\mathrm{Beta}(a+x, b+(M-x)) = \\frac{\\mathrm{Binom}(M,x|\\theta) \\mathrm{Beta}(\\theta|a,b)}{\\int \\mathrm{Binom}(M,x|\\theta) \\mathrm{Beta}(\\theta|a,b)\\ \\mathrm{d}\\theta}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(X=x|M) &= \\int \\mathrm{Binom}(M,x|\\theta) \\mathrm{Beta}(\\theta|a,b)\\ \\mathrm{d}\\theta \\\\\n",
    "         &= \\frac{\\mathrm{Binom}(M,x|\\theta) \\mathrm{Beta}(\\theta|a,b)}{\\mathrm{Beta}(a+x, b+(M-x))} \\\\\n",
    "         &= {M \\choose x} \\frac{\\theta^x (1-\\theta)^{M-x} \\Gamma(a+b) \\theta^{a-1} (1-\\theta)^{b-1} \\Gamma(a+x)\\Gamma(b+(M-x))}{\\Gamma(a+b+M) \\theta^{a+x-1}(1-\\theta)^{b+M-x-1}\\Gamma(a)\\Gamma(b)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial model**\n",
    "\n",
    "$$\n",
    "P(k_1, \\ldots, k_n|m, \\mathbf{\\theta}) = \\begin{pmatrix} m \\\\ k_1 \\cdots k_n \\end{pmatrix} \\theta_1^{k_1} \\cdots \\theta_n^{k_n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjugate prior is the Dirichlet distribution:\n",
    "\n",
    "$$\n",
    "P(\\theta_1, \\ldots, \\theta_n|\\mathbf{\\alpha}) = \\frac{\\Gamma(\\alpha_1 + \\cdots + \\alpha_n)}{\\Gamma(\\alpha_1)\\cdots\\Gamma(\\alpha_n)} \\theta_1^{\\alpha_1-1} \\cdots \\theta_n^{\\alpha_n-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have $N$ dice rolls with $\\mathcal{D}=\\{x_1, \\ldots, x_N\\}$ where each $x_i \\in \\{1, \\ldots, K\\}$. The likelihood (sample distribution) is\n",
    "\n",
    "$$\n",
    "P(X_1=x_1, \\ldots, X_n=x_n|\\mathbf{\\theta}) = \\theta_{x_1}  \\cdots \\theta_{x_N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $N_k$ be the number of rolls where $k$ came up. This is a sufficient statistics $\\mathbf{T}(\\mathbf{x}) = (N_1, \\ldots, N_k)^T$ since\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}|\\mathbf{T}(\\mathbf{x})) = \\theta_1^{N_1} \\cdots \\theta_K^{N_k} = P(\\mathbf{T}(\\mathbf{x})|\\mathbf{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the maximum likelihood of Dirichlet by maximizing log-likelihood under the constraint that $\\sum_i \\theta_i = 1$.\n",
    "\n",
    "The Lagrangian is then \n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{\\theta}, \\lambda) = (\\alpha_1-1) \\log \\theta_1 + \\cdots + (\\alpha_n-1) \\log \\theta_n - \\lambda (\\theta_1 + \\cdots + \\theta_n - 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\partial_{\\theta_i} \\mathcal{L} = \\frac{\\alpha_i - 1}{\\theta_i} - \\lambda\n",
    "$$\n",
    "\n",
    "So \n",
    "$$\n",
    "\\lambda \\theta_i = \\alpha_i - 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\partial_\\lambda \\mathcal{L} = \\sum_i \\theta_i - 1 = \\sum_i \\frac{\\alpha_i - 1}{\\lambda} - 1\n",
    "$$\n",
    "\n",
    "So\n",
    "$$\n",
    "\\lambda = \\sum_i (\\alpha_i - 1)\n",
    "$$\n",
    "\n",
    "And then \n",
    "$$\n",
    "\\theta_i = \\frac{\\alpha_i - 1}{\\sum_i (\\alpha_i - 1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d example: coin flips with $\\theta$.\n",
    "\n",
    "1. Learning phase:\n",
    "Posterior distribution for $\\theta$. $\\mathcal{D} = \\{H,T,T,H, \\ldots\\}$ or, more concisely, $(N,k)$.\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}) = \\frac{p(\\mathcal{D}|\\theta) p(\\theta)}{\\int \\cdots}\n",
    "$$\n",
    "\n",
    "where $p(\\mathcal{D}|\\theta)$ is Binomial distribution and $p(\\theta)$ is a Beta-distribution.\n",
    "\n",
    "2. Posterior-predictive distribution\n",
    "\n",
    "$$\n",
    "p(k|N, \\mathcal{D}) = \\mathrm{Binom}(N,k,\\theta) p(\\theta|\\mathcal{D})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes classifier**\n",
    "\n",
    "Data is $\\mathcal{D}=\\{\\mathbf{x}_1, \\mathbf{x}_2, \\ldots\\}$. Parameter for each class $c$ is $\\theta_{i,c}$ where $i \\in \\{1, \\ldots, K\\}$ if each class-conditional distribution has $K$ parameters (e.g. one for each dimension in Bernoulli model, two for each dimension in Gaussian etc.)\n",
    "\n",
    "$$\n",
    "p(\\mathbf{\\theta}|\\mathcal{D}) = \\frac{p(x_1^1, x_1^2, \\ldots|\\mathbf{\\theta}_1)p(\\mathbf{\\theta_1}) p(x_2^1, x_2^2, \\ldots|\\mathbf{\\theta}_2)p(\\mathbf{\\theta_2}) \\cdots}{\\int \\cdots} = \\frac{p(x_1^1|\\theta_1)p(x_1^2|\\theta_1)\\cdots p(x_2^1|\\theta_2)p(x_2^2|\\theta_2)\\cdots}{\\int \\cdots} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior predictive probability\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(y = c | \\mathbf{x}, \\mathcal{D}) & \\propto P(\\mathbf{x} | y = c, \\mathcal{D}) P(y=c|\\mathcal{D}) \\\\\n",
    "& = P(y=c|\\mathcal{D}) \\prod_{j = 1}^D P(x_j | y=c, \\mathcal{D}) \\\\\n",
    "& =  \\int P(y=c|\\mathbf{\\pi}) P(\\mathbf{\\pi}|\\mathcal{D})\\ \\mathrm{d}\\mathbf{\\pi} \\prod_j \\int P(x_j|y=c, \\mathbf{\\theta}) P(\\mathbf{\\theta}|\\mathcal{D})\\ \\mathrm{d}\\mathbf{\\theta}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.1**\n",
    "Beta-binomial model with uniform prior $\\alpha=\\beta=1$. Derive MLE by elementary calculus.\n",
    "\n",
    "$$\n",
    "P(\\theta|\\mathbf{x}) \\propto {N \\choose k} \\theta^k (1-\\theta)^{N-k} = \\frac{N!}{k! (N-k)!} \\theta^k (1-\\theta)^{N-k}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}\\theta} P(\\theta|\\mathbf{x}) &= \\frac{N!}{k! (N-k)!}\\left[k \\theta^{k-1} (1-\\theta)^{N-k} - \\theta^k (N-k) (1-\\theta)^{N-k-1} \\right] \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "k \\theta^{k-1} (1-\\theta)^{N-k} - \\theta^k (N-k) (1-\\theta)^{N-k-1} &= 0 \\\\\n",
    "\\theta^{k-1} (1-\\theta)^{N-k-1} \\left[k (1-\\theta) - \\theta (N-k)\\right] &= 0 \\\\\n",
    "k - \\theta k - \\theta N + \\theta k &= 0 \\\\\n",
    "\\theta = \\frac{k}{N}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.2**\n",
    "$$\n",
    "\\begin{align}\n",
    "p(D) &= \\frac{\\Gamma(\\alpha_1 + N_1) \\Gamma(\\alpha_0 + N_0) \\Gamma(\\alpha_1 + \\alpha_0)}{\\Gamma(\\alpha_1+\\alpha_0+N)\\Gamma(\\alpha_1)\\Gamma(\\alpha_0)} \\\\\n",
    "     &= \\frac{(\\alpha_1 + N_1-1)! (\\alpha_0 + N_0 - 1)! (\\alpha_1 + \\alpha_0 - 1)!}{(\\alpha_1+\\alpha_0+N - 1)! (\\alpha_1-1)!(\\alpha_0-1)!} \\\\\n",
    "     &= \\frac{(\\alpha_1 + N_1-1)!}{(\\alpha_1-1)!} \\frac{(\\alpha_0 + N_0 - 1)!}{(\\alpha_0-1)!}\\frac{(\\alpha_1 + \\alpha_0 - 1)!}{(\\alpha_1+\\alpha_0+N - 1)!} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.3**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x|n,\\mathcal{D}) &= \\frac{\\Gamma(x+\\alpha_1')\\Gamma(n-x+\\alpha_0')}{\\Gamma(x+\\alpha_1'+n-x+\\alpha_0')} \\frac{\\Gamma(\\alpha_1'+\\alpha_0')}{\\Gamma(\\alpha_1')\\Gamma(\\alpha_0')} {n \\choose x}\\\\\n",
    "&= \\frac{\\Gamma(x+\\alpha_1')\\Gamma(1-x+\\alpha_0')}{\\Gamma(x+\\alpha_1'+1-x+\\alpha_0')} \\frac{\\Gamma(\\alpha_1'+\\alpha_0')}{\\Gamma(\\alpha_1')\\Gamma(\\alpha_0')} \\frac{1!}{x!(1-x)!}\\\\\n",
    "&= \\frac{(x+\\alpha_1'-1)!(1-x+\\alpha_0'-1)!}{(x+\\alpha_1'-x+\\alpha_0')!} \\frac{(\\alpha_1'+\\alpha_0'-1)!}{(\\alpha_1'-1)!(\\alpha_0'-1)!} \\frac{1}{x!(1-x)!}\\\\\n",
    "&= \\frac{(x+\\alpha_1'-1)!(-x+\\alpha_0')!}{(\\alpha_1'+\\alpha_0')!} \\frac{(\\alpha_1'+\\alpha_0'-1)!}{(\\alpha_1'-1)!(\\alpha_0'-1)!} \\frac{1}{x!(1-x)!}\\\\\n",
    "&= \\frac{(\\alpha_1')!(-1+\\alpha_0')!}{(\\alpha_1'+\\alpha_0')!} \\frac{(\\alpha_1'+\\alpha_0'-1)!}{(\\alpha_1'-1)!(\\alpha_0'-1)!} \\frac{1}{1!0!}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.4** Beta updating from censored likelihood\n",
    "(Source: Gelman.) Suppose we toss a coin $n = 5$ times. Let $X$ be the number of heads. We observe that\n",
    "there are fewer than 3 heads, but we don't know exactly how many. Let the prior probability of heads be\n",
    "$p(\\theta) = \\mathrm{Beta}(\\theta|l, 1)$. Compute the posterior $p(\\theta|X < 3)$ up to normalization constants, i.e., derive an\n",
    "expression proportional to $p(\\theta, X < 3)$. Hint: the answer is a mixture distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(\\theta|\\mathcal{D}) \\propto P(\\mathcal{D}|\\theta) P(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "P(\\theta|X<3) & \\propto P(X<3|\\theta)P(\\theta) \\\\\n",
    "              &= \\sum_{k=0}^2 {n \\choose k} \\theta^k (1-\\theta)^{n-k} \\frac{\\Gamma(l+1)}{\\Gamma(l)\\Gamma(1)} \\theta^{l-1} (1-\\theta)^0 \\\\\n",
    "              &= \\sum_{k=0}^2 \\frac{l! n!}{(l-1)! k! (n-k)!} \\theta^{k-l-1} (1-\\theta)^{n-k}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.5**\n",
    " Let $\\phi(\\theta) = \\log \\frac{\\theta}{1-\\theta}$. Show that $p(\\phi) = \\mathrm{const} \\Rightarrow p(\\theta) \\propto \\mathrm{Beta}(\\theta|0,0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "P(\\phi)\\ \\mathrm{d}\\phi &= P(\\theta) |\\partial_\\theta \\phi(\\theta)|\\ \\mathrm{d}\\theta \\\\\n",
    "                        &\\propto \\left|\\frac{1-\\theta}{\\theta} \\left[(1-\\theta)^{-1} - \\theta (1-\\theta)^{-2}\\right]\\right|\\ \\mathrm{d}\\theta\\\\\n",
    "                        &= \\frac{ P(\\theta)}{\\theta (\\theta-1)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy, sympy.plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = sympy.symbols(\"theta\", Reals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{1}{\\theta \\left(\\theta - 1\\right)}$"
      ],
      "text/plain": [
       "-1/(theta*(theta - 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sympy.simplify(sympy.diff(sympy.log(theta/(1-theta)), theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/sympy/plotting/experimental_lambdify.py:233: UserWarning: The evaluation of the expression is problematic. We are trying a failback method that may still work. Please report this as a bug.\n",
      "  warnings.warn('The evaluation of the expression is'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAEqCAYAAACfhL4MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsU0lEQVR4nO3de3xV1Z3//9dKQkLukBskJFxCuIaGAAFBRSuKICpq1RbbGe04DtXaamfa6ddO66Ot/fX39daZ+Y5+KxPb6sy01lanbUYEaq1gq0UgIPdbINxyv9/J5Zyzvn8kRAiBHCDJ2eec9/PxOA9zzl5n53M2cN6utdde21hrERER8Wchvi5ARETkSinMRETE7ynMRETE7ynMRETE7ynMRETE7ynMRETE7ynMRETE7ynMRETE7ynMRETE74UN1MAYswj4K2AxkAqcBvYCbwM/t9Y2DmmFIiIiAzAXW87KGLMeKAMKgEKgChgJTAVuAG4H/tla+z9DX6qIiEj/BgqzJGttzUV34EUbERGRoXTRMBMREfEHXk0AMcYsNMZsM8a0GGM6jTFuY0zTUBcnIiLiDW9nM74I3AcUAZHAQ8ALQ1WUiIjIpRhwNuMZ1tojxphQa60beMUY85chrEtERMRr3oZZmzEmHNhpjHkWKAeih64sERER73k7zPjXPW2/ArQCGcBnhqooERGRS+FtmN1prW231jZZa79vrf0H4LahLExERMRb3obZA/289sVBrENEROSyXfScmTHmPuDzwCRjzNmrfMQBtUNZmIiIiLcGmgDyF7oneyQBPzrr9WZg91AVJSIicim8XgHEGDMBmGKtfdcYEwmEWWubh7Q6ERERL3i7AsjfAW8C/97zUjrwuyGqSURE5JJ4e53Zo8ACYAuAtbbIGJMyZFX174oXkVy+fDkbNmwYjFpEROTKmMHcmbezGTustZ29FRgTxiCEy3CrqdHi/iIigcjbMHvfGPNPQKQxZinwBvDW0JUlIiLiPW/D7AmgGtgDfAlYB3xnqIoSERG5FF6dM7PWeoCXex4iIiKO4lWYGWOuAb4HTOh5jwGstTZz6EoTERHxjrezGX8K/D2wHXAPXTkiIiKXztswa7TWrh/SSkRERC7TQGszzu35caMx5jngN0DHme3W2h1DWJuIiIhXBuqZ/ajP87yzfrbAksEtR0RE5NJdNMystTcAGGMyrbXFZ28zxmjyh4iIOIK315m92c9rbwxmISIiIpdroHNm04FsIN4Y85mzNsUBI4eyMBERcZ4PimrI/3Mxz9+bQ0qsc2JgoHNm04DbgFHA7We93gz83RDVJCIiDlXeeJo/Ha6mo8vj61LOMdA5swKgwBizyFq7eZhqEhERhzpzC0wzqGveX7mLnjMzxnzHGDP6QkFmjFlijLltaEoTERGnsT03TAlxWJoNNMy4B1hrjGkHdtC92PBIYAqQC7wL/P9DWaCIiDiHx6E9s4HC7B5r7TXGmG8CVUAq0AT8HFhtrT091AWKiIhz9A4zDu69Na/YQGE2zxgzAfgCcEOfbZGAwkxEJIh8Mszo40L6GCjM1gAbgEyg8KzXDd0rgOjCaRGRIHJmmNFhHbOLTwCx1v6btXYG8DNrbeZZj0m6/YuISBDqGWd02jCjVyuAWGsfGepCRETE+c50zJw2zOjtclYiIiJEhIWQN2F0b6g5hcJMRES81trhpvBEPWEO65opzERExGuennNmIQozERHxV2fCLNRhV00rzERExGvunvWFnbaclcJMRES89skwo48L6cNh5XQzxkwzxuw869H0r//6r+e02bRpE/Hx8eTm5pKbm8tTTz3lm2JFRIKIx+OfCw37hLX2EN0LGWOMCQVK77rrrti+7RYvXszatWuHuToRkeDl1jmzy3YjcHTChAm+rkNEJOidWc5Ksxkv3Srgl/1t2Lx5M7Nnz+aWW25h3759w1yWiEjwiY4IZWFmgq/LOI+jw8wYEw6sBN7ou23u3LmcOHGCXbt28dWvfpU777yz333k5+eTl5dHXl4e1dXVQ1uwiEiAq2vt5OOTDb4u4zyODjPgFmCHtbay74a4uDhiYmIAWLFiBV1dXdTU1Jy3g9WrV1NYWEhhYSHJyclDXrCISCDrcllGhDovOpxX0bnu4wJDjBUVFdieE5Fbt27F4/GQmJg4nLWJiAQdl8fDiFBnnS8Dh85mBDDGRAFLgS+deW3NmjUAPPzww7z55pu89NJLhIWFERkZyeuvv45x2OwaEZFA0+X2EObAnpk507vxA1dcaF5eHoWFhQM3FBGRfn3jjV1sPlrLh08sudJdDWrvw3nxKiIijtXdM3PeKJjCTEREvOZyawKIiIj4uU63x3H3MgOFmYiIXAKX20N4mPOiw7GzGUVExHnGxI0kMSbc12WcR2EmIiJeO1zZTFS486LDeX1FERFxrLZON5Hhob4u4zwKMxER8drpLjdRCjMREfFnbZ0KMxER8XOnO91EjtA5MxER8VPWWto6XeqZiYiI/+pwefBYNAFERET8V1uHi+TYCGJHaphRRET8VFO7i+rmDqJ1nZmIiPir2tZOABIcuAKIwkxERLxS3xNmidEKMxER8VN1PWE2OkphJiIifurMMKMTFxpWmImIiFfq2zoZOSJECw2LiIj/qm3pJMGBQ4ygMBMRES81t3c5cogRFGYiIuKl47WtjBsV6esy+qUwExGRAbk9luO1bYxPjPZ1Kf1SmImIyIDKGk7T6fKQmaQwuyTGmOPGmD3GmJ3GmMK+2621PPbYY2RlZZGTk8OOHTt8UaaISFA4VtMKwCSHhpnz5lee6wZrbU3Pz/bsDevXr6eoqIiioiK2bNnCI488wpYtW3xQoohI4OsNs2Rnhplje2YDKSgo4P7778cYw8KFC2loaKC8vNzXZYmIBKRjNa3ERISRHBPh61L65eQws8A7xpjtxpjVfTeWlpaSkZHR+zw9PZ3S0tLzdpKfn09eXh55eXlUV1cPacEiIoGquKaVSUnRGGN8XUq/nBxm11hr5wK3AI/+6U9/Omejtfa8N/R3kFevXk1hYSGFhYUkJycPUakiIoHtWE2LY8+XgYPDzFpb1vPfKuC3W7duPWd7eno6p06d6n1eUlJCWlrasNYoIhIMyhtPU95wmoWZCb4u5YIcGWbGmGhjTOyZn4GbZ82adU6blStX8p//+Z9Ya/noo4+Ij48nNTXVF+WKiAS0jQercXkgb6Jzw8ypsxnHAL/tGTYMA15bvnz5ojVr1gDw8MMPs2LFCtatW0dWVhZRUVG88sorPixXRCRwbTxUxbhRkUxJifF1KRdk+jv35FBXXGheXh6FheddsiYiIhfQ4XIz56k/cPfcdH5w56yB3+C9QZ1J4shhRhERcYYtxXW0dbpZMj3F16VclMJMREQuaOOhKiLCQliYmejrUi5KYSYiIhe08WAVV09OJDI81NelXJTCTERE+lVc3cLx2jbHDzGCwkxERC7gvYNVAHx6msJMRET8kLWWwuN1LJmeQkZClK/LGZDCTEREzrN2dzkb9lVy88wxvi7FKwozERE5R3uXm6fXH2Rmahz35mUM/AYHUJiJiMg5fvLnYkobTvPkbTMJDXHmKvl9KcxERKRXZVM7P950lOXZY1k02dnXlp1NYSYiIr2e3XAIl9vyTytm+LqUS6IwExERAHaXNPDfO0p48NpJjE90/gzGsynMREQEay1PvbWfpJhwHr1hsq/LuWQKMxER4Tcfl1J4op5v3DyN2JEjfF3OJVOYiYgEuR0n6/nBW/v43PwMv5mK35fCTEQkiO0tbeSBn20lPiqcry+d6jdT8ftSmImIBKnDlc3c/7OtxI0cwS8euoqUuJG+LumyKcxERILQsZpWvvCTLYSFGH7x0FWkj/av2Yt9hfm6ABERGV4l9W184eWPcHssv1q9kIlJ0b4u6YqpZyYiEkSO1bTw+Ze30NLh4r/+dgFTxsT6uqRBoTATEQkSa3eXsfLFD8lKieY/HlxAdlq8r0saNBpmFBEJcK0dLr7/1j5+XVhCbsYovnf7LL9b4WMgCjMRkQC2p6SRx17/mOO1rXzlhiwev2kKI0IDb1BOYSYiEoA8HsvLfy7m+XcOkRQTwS//biELM/1nFfxL5ch4NsZkGGM2GmMOGGP2GWMe79tm06ZNxMfHk5ubS25uLk899ZQvShURcZzDlc18/Y1d/O/1B7lx+hjWP744oIMMnNszcwFft9buMMbEAtv379/PzJkzz2m0ePFi1q5d65MCRUScpqqpnX/+w2F+XXiKjIQonr07h3vz0jHGP1f1uBSODDNrbTlQ3vNzszHmQGlp6ZS+YSYiIt0TPP79T8W8/KdiXB4PX7x6El9dksXo6HBflzZsHBlmZzPGTATmXHXVVedt27x5M7NnzyYtLY3nn3+e7Ozs89rk5+eTn58PQHV19RBXKyIyfDpcbn6zo5QfvXOYmpYObs1J5ZvLpjEh0f8vgr5Uxlrr6xouyBgTA7wP/NBa+99nb2tqaiIkJISYmBjWrVvH448/TlFR0UX3l5eXR2Fh4RBWLCIy9BpPd/GLLSd49cPjpI+OIjQE/mnFDOaMH+3r0i7FoI59OjbMjDEjgLXA7621/wxctNCJEydSWFhIUlLSBdsozETEn5U2nOZnHxzj9a0nae10c21WEl+6LpNrpyT543mxQS3YkcOMpvtP5afAgZ4gO09FRQVjxozBGMPWrVvxeDwkJgb2bB0RCT4ej2VzcS2vbT3J5qO1NJ7u4racVP5ucSazxgXOCh5XypFhBlwD/DWwxxizE+Dtt9/m5MmTADz88MO8+eabvPTSS4SFhREZGcnrr7/uj/9nIiLSr6rmdt7cXsLrW09xsq6N+MgRfOm6TFbmpvn9CvdDwbHDjP244kI1zCgiTtbe5ea9g1VsOlTFb3aU4vJYrpqUwOevGs+y7LGMHBHq6xIHU+APM4qIBAuX28OWY7UU7Cxj/Z4KmjtcJMeE8+VPT+aOOeOYnBzj6xL9gsJMRGSYdbo8bC6uZcPeCv6wv4L4yBFUNnWwfNZY7swdx6LJiYSG6LTJpVCYiYgMg7ZOF385Wsu63eW8e6CSpnYX0eGh3DA9hTtyx7F4SlKgDSMOK4WZiMgQOVXXxsZDVfzxQBWbi2vJTY/nUGULS2eO5ZZZY7lWATZoFGYiIoPkdKebLcdq+XNRDRWNp3l7TwUAk5Ki+euFE7hxRjLzJyYG5C1YfE1hJiJymdwey/6yJj4+Wc87+yvZeryOTpeH8LAQbskey3duncGS6SlkahLHkFOYiYh4yeOxHKps4qPiOv5ytJYtxbU0tbuYnRFPe6eHBxZNYPGUZBZMStDw4TBTmImIXIDL7WFfWRNbj9Wx5Vgd247X0Xi6i4TocGIiwljxqVQWTU5k4aQExsRH+rrcoKYwExHp0Xi6i49P1rPjRD3bT9ZjgA+O1ALd572WZ49lwaQEFmYmME6rcDiKwkxEgpLHYzla3cLHJ+vZeaqR7SfqOVzVjLUQYmBGahxLpqewasF4FkxMICVupK9LlotQmIlIUKhqamdvaSPbT9az81QDu0810tzhAmDWuDhSR43ktpxU5k0YzeyMUURH6OvRn+hPS0QCTl1rJ/vLmth5qp7dJY3sLmmkoqmd+RNHs+NkA9PHxrIyN43cjFHMGT+KzKQYQrTihl9TmImIX6tqamdfeRN7SxrZW9bI3tImShtOMzsjnl2nGpmUFM1VmQnkpI8iN2MUM1PjiAzXTMNAozATEb/g8VhO1LVxoLyJfWWN7C9rYn95E6OjwjlY0Qx0T9KYO2E09y+awOz0UcxIiyM+coSPK5fhoDATEcdp63RRVNnCvrImDpR3h9bB8iYyEqI4WNFMaIghKzmGayYnkTdxNJnJMWSnxRE7UsEVrBRmIuIzHo/lZF0bByuaKapqZn9ZEwcrmjle28qn0uLZXdpITEQYM1JjuXteOnPGj2JycgxTx8TqomQ5h8JMRIactZbq5g4OVTZzqKKZ6uYOPiqu5XBlC6e73ABMTIzCGMP0sbHcmTuOmWmxTB8bR/roSN1FXgakMBORQVXb0kFRVQtFlc0cqmzmcGULlU3tnKht621zw7RkYkaGcd+C8UwfG8vUsbFkpUQTE6FhQrk8CjMRuWTWWmpbOymqbOF4bSv7y5ooqmqmqLKFTreH5vbu67diI8KYOjaWZdljSY0fybQx3cGVFBPh408ggUZhJiIXZK2loqmdI1UtHKlqobalk63H6iiqaqa+rQuAORmjOFLVQtaYGG6aMYYpY2KYkhLD1LGxjI0bqSFCGRYKMxHB5fZwsq6tO7SqWzha1UptaweFx+tp6VklA+D6qUl4rGX5rLFkpcQyJaU7uMbGK7TEtxRmIkGktcPFsZpWjlS1cLS6pfe/CdHhfFRc19tuTFwE12Ylc/fccWSlxJCVEktWSgxJMeEKLXEkhZlIgLHWUtnUwdHqFoqrW6hr7aTwRD1Hq1ooa2wHYEJiFCX1p5mQEEVmcgzzxo/innkZTE6OZnJKDHG6Xkv8jGPDzBizHPg/QCjwE2vtOduttTz++OOsW7eOqKgoXn31VebOneuLUkV8or3LzYnaNo5Wt3C0p4dVXNNKVHjoOb2sBRMT6HC5WZiZyOSUGCYnR5OZHMPExGjCw0J8+AlEBo8jw8wYEwr8X2ApUAJs279/PzNnzuxts379eoqKiigqKmLLli088sgjbNmyxUcViwyNM9dnHa1u5URdK4crWiiu6Q6ukvrTZCXHUFTVAsC4UZFkJkeTN2E0t34qlcnJMUxOiSElNkJDgxLwHBlmwALgiLW2GMAY83pBQUHO2WFWUFDA/fffjzGGhQsX0tDQQHl5Oampqb6qWeSytXe5OV7bytGqVoqrWzhW28rRqhaKq1t7b1MyItQQERbKhMQocjNGc/fcdCYnx5CZHM2kpGiiwp36z1lk6Jm+w3dOYIy5B1hurX2o5/lfjx8//j+Tk5N72xw5coSxY8cSExMDwOHDh0lPTycq6ty7v1ZXV1NTUwNAR0cHubm5w/Mh/EB1dTVnH9NgNxzHo8vtocPlodPlod3lprPLgzGGpvauc9qNCA0hckRob4BFjAghIiyEEaHDNyyovx/n0vH4xGAci+3bt//eWrt8kEpybM/svDGRlStX8sILL/Q+v/XWW/nWt77FtddeC8CNN97Is88+y7x58y640+joaAoLC4egXP+Ul5en43GWwToe7V1uTtS0crSmp3dV09ozGaOVsFBDe8/1WfEjQslMjmZhZiKxI8PITI4hMymazGRn9LL09+NcOh6fGKRjMWhBBs4NsxIg46zn6Wlpaec0SE9P59SpU5+8oaSEvm1EhsqZFTCOVrX0LpRbXN3C0epWSurbCA8Nod3lASAtfiSTU2K4e+44ZqTGkT46iszkaMbGjdQNIUUGiVPDbBswxRgzCSgFVq1cufKcBitXruTFF19k1apVbNmyhfj4eJ0vk0Hncns4VX+aoz0XEze0da+AcbS6lcbT3T2skWEhGGOYmBRNTno8d80ZR2ZydO+sQSf0skQCnSP/lVlrXcaYrwC/p3tq/s+ys7Nz1qxZA8DDDz/MihUrWLduHVlZWURFRfHKK68MuN+kpKQhrdvfrF692tclOEZbp4uVDzxKwc5SjlS10NLh4sMjNRyvaaPT7eltt2R6MuFhIdyW88lswcnJ0aTGjSR0GM9nDQf9/TiXjscnnHgsHDkB5AKuuFCNeUtjWxdHqps5UtVCUWULbV1u3j9UTWnD6d42IQauyUoiIiyUrJ6wykqJITM5RnctFhk8gzrG7siemciVqmvtpKiyufdWJKe73Gw8VE11c0dvm4iwEG6eOYa5E0bz2byMnmWbYpiYFEVEmG78KOJPFGbi1+pbOzlc2czhqhaO1bSwv6yJI1Ut1LR09raJDg/lmqwkrp+azJSewJqSEsu40ZGEagKGSEAIrEH+Hhs2bGDatGlkZWXx9NNPn7fdWstjjz1GVlYWOTk57NixwwdVDo+BjsUvfvELcnJyyMnJ4eqrr2bXrl0+qHJgrR0uPj5Zz6+2neT7b+3j73/1MfN/+C5zfvAHPpf/EU/+bi+/3noKg2HJ9BS+c+sMXv2b+fzliSXs/f4y8u/P4/l7ZzPhdBFfvvM6llyVw3PPPnPB37dt2zZCQ0N58803h/FTDr+B/n4AbNq0idzcXLKzs7n++uuHucLhNdDxaGxs5Pbbb2f27NlkZ2d7da7enz344IOkpKQwa9asfrc76rvUWusvD6+4XC6bmZlpjx49ajs6OmxOTo7dt2+ftdbaefPmWWutffvtt+3y5cutx+OxmzdvtgsWLPB2937lYsfijA8//NDW1dVZa61dt26dz49Fl8ttiyqb7Fu7Su1Lm4rs3766zV77zB/thP+1tvcx/Tvr7WO/3GG//uud9t/fP2I3Hqy0pfVt1uPxXHTf3hyPM+1uuOEGe8stt9g33nhjqD6qz3lzPOrr6+2MGTPsiRMnrLXWVlZW+qLUYeHN8fjhD39ov/nNb1prra2qqrKjR4+2HR0dvih3WLz//vt2+/btNjs7u9/tV/hdOqgZEXDDjFu3biUrK4vMzEwAVq1aRUFBAcG4FJY3x+Lqq6/u/XnhwoWUlJQMW331rZ0cKO8eFtxd2sjBiiYOV7bQ2XN91sLMBGpbOslJH8Vn52UwdWws08fGkjE66rKuz/LmeAC88MIL3H333Wzbtu3KP6SDeXM8XnvtNT7zmc8wfvx4AFJSUnxS63Dw5ngYY2hubsZaS0tLCwkJCYSFBdzXaK/rrruO48ePX3C7k75LA+5PobS0lIyMT663Tk9PP28B4v7alJaWBlyYeXMszvbTn/6UW265ZdDr8Hgsp+rbOFzZzM5TDRwob2Z/WRMVTd23IxkRakiIDmfqmFi+ePVEpo2JZXpq9/2zBnMihrd/N37729/y3nvvBXyYeXM8Dh8+TFdXF5/+9Kdpbm7m8ccf5/777x/uUoeFN8fjK1/5CitXriQtLY3m5mZ+9atfERISkGdrvOKk79KACzPbz6UGfVcM96ZNILiUz7lx40Z++tOf8sEHH1zR73S5PRRVtrCvvIl9ZY3sK2viQFkTzR0uZqfHs7esiazkGBZmJjAjNY6ZaXHMSI0jKSbiin6vN7w5Hl/72td45plnCA0N/NmM3hwPl8vF9u3b+eMf/8jp06dZtGgRCxcuZOrUqcNV5rDx5nj8/ve/Jzc3l/fee4+jR4+ydOlSFi9eTFxc3HCV6ShO+i4NuDDzZpmrYFkKy9vPuXv3bh566CHWr19PYmKi1/t3uT0cqW5hT0kje0q7HwfKm0iLj6S4ppWRI0KYkRrHHXPSmJUWz8y0OKaOiWXkCN8EhTfHo7CwkFWrVgFQU1PDunXrCAsL48477xzOUoeFt/9WkpKSiI6OJjo6muuuu45du3YFZJh5czxeeeUVnnjiCYwxZGVlMWnSJA4ePMiCBQuGu1xHcNR36WCfhBvCh1e6urrspEmTbHFxce9J3L1791prP5kAsnbt2nNOWs6fP9/b3fuVix2LM06cOGEnT55sP/zww4vuy+Px2BM1rbZgZ6l96q199p6XPrSff/mj3kkZM59cb+9d8xf7g7f22bW7Sm1RZZN1uS8+IWO4eXM8zvbAAw8E9AQQb47H/v377ZIlS2xXV5dtbW212dnZds+ePT6qeGh5czwefvhh+93vftdaa21FRYVNS0uz1dXVPqh2+Bw7duyCE0Cu8LtUE0AuJiwsjBdffJFly5bhdrt58MEHyc7OZs2aNVRXVwNc1lJY/uhixwK6lwV76qmnqK2t5ctf/nLvewoLC2lq72LXqQZ2nGigurmdt/eUU9+z2ntEWAizxsUzf+Jo7p2Xzqxx8WQmRTt+0Vxvjkcw8eZ4zJgxg+XLl5OTk0NISAgPPfTQBadp+ztvjseTTz7JF7/4RT71qU9hreWZZ54J6GXy7rvvPjZt2kRNTQ3p6el8//vfp6ur+3vgcpcVHCpazkqw1nK8to1tx+vYeaqBwuN1FFW1YC0YA9dPSWZM3EhmZ4xidkY8U8fEDut9tUQkIGk5K7kyLreHA+VNbDlWx7bjdWw/Ud+7Ysbc8aNIGxXJbTlpzBk/itkZo4gbqfUIRcTZFGZBwOX2sLesiY+Ka/mouJbC4/VMTo5mV0kj4xOiuG5qMvMnJpA3YTSTk2McP1woItKXwiwAeTyWAxXd4fXnwzUUnqinpcMFQFZKDHfOSWNRZiLzJyaQEjfSx9WKiFw5hVmAqGxs5/2iaj4oquHDIzXUtnYPGy6YlMCdc9JYmJnIVZMSSY4d+uu5RESGm8LMT7k9lo9P1rPxUBXvHazmcEUTkeFhjBwRyuIpSVw7JZlrs5IYG6+el4gEPoWZH2lu7+LDIzWs31vB+4eraWjrIjTEMG/CaL6xbDo3TEtm2tjYgFzNREScq6Ghgddee40vf/nLbNq0ieeff561a9d6/X5jzBeBd6y1ZZdbg8LM4epaO3l3fyUb9lXwQVENLo+H8QlRLJmewpLpKSzOSiY+SrMNRcR3Ghoa+PGPf9x7vepl+CKwF1CYBZLG011s2FvOR8V1FOwsxWMhfXQk9y+awLJZY5mTMYowXeclIg7xxBNPcPToUXJzcxkxYgTR0dHcc8897N27l3nz5vHzn/8cYwzbt2/nH/7hH2hpaWHHjh2/pzvErgHygF8YY04Di4B/BG4HIoG/AF+yA1wUrYumHaK9y82mQ1X87uMy3jtURafLw6TEKFbmjuPm7DHMTI3T8KGIONLx48e57bbb2Lt3L5s2beKOO+5g3759pKWlcc011/Dcc89x1VVXcf3111NQUEBycjLGmFXAMmvtg8aYTcA3rLWFAMaYBGttXc/P/wX82lr71sVqUM/Mx3aXNLBhXwX/tfkEze0ukmIi+MJV47kzdxw56fEKMBHxOwsWLCA9PR2A3Nxcjh8/zqhRo9i7dy9Lly490+w7QPkFdnGDMeabQBSQAOwDFGZO09LhomBnKb/cepK9pU3EhIdyy6dSuX12GldPTtQQooj4tYiITy4BCg0NxeVyYa0lOzubzZs3n9n0qf7ea4wZCfwYyLPWnjLGfA8YcFq2wmwYHatp5Xcfl/CTPx+jtdPN9LGxPHVHNnfOGaclo0TEb8XGxtLc3HzRNtOmTaO6uprNmzezaNEijDEjgKnW2n1AMxDb0/RMcNUYY2KAe4A3B6pBYTYMPj5Zz7+/X8zv91cQEx7KrTmprFownjkZozSMKCJ+LzExkWuuuYZZs2YRGRnJmDFjzmsTHh7Om2++yWOPPUZjYyPATuBf6R5CfBVYc9YEkJeBPcBxwKtbvjtuAogx5jm6Z7F0AkeBv7HWNtBnAsjEiROJjY0lNDS097YlAxnOCSDWWj48UsO/vXeErcfqiBsZxv2LJvLA1RO1CoeISBCsmv8H4FvWWpcx5hngW8D/6q/hxo0bHXkvoe0n6nh6/UHqWztp63Lz5G0z+dz8DGIinHi4RUT8n+O+Xa2175z19CO6x0v9wpGqZp7dcIh39leSHBvB126awj1z04kYEerr0kREAprjwqyPB4Ff9bfBGMPNN9+MMYYvfelLrF69ut8d5Ofnk5+fD9B7p+nBVt/ayct/LmbN+0eJCg/j60un8reLJxEV7vTDKyISGHxyzswY8y4wtp9N37bWFvS0+TbdV4V/pufK73MKLSsrIy0tjaqqKpYuXcoLL7zAddddd9HfOxTnzNbvKefJgr2kxI5kwaQEvroki8QYnRMTERmA/58zs9bedLHtxpgHgNuAGy+0hElaWhoAKSkp3HXXXWzdunXAMBtM1c0dfPd/9rJuTwXZaXE8d89sZqbFDdvvFxGRTzju6lxjzHK6J3ystNa29demtbW195qG1tZW3nnnHWbNmjVsNf5hXyU3/8v7vLu/in9cNo3fPXqNgkxExIeceFLnRSAC+EPPNVgfWWsfLisr46GHHmLdunVUVlZy1113AeByufj85z/P8uXLh7wwt8fy7IaD/GZHKdPGxvL/3TmLrJTYgd8oIiJDynHXmV2ETxcabulw8bXXP+bdA1X81cLxfPf2bEZo2SkRkcvl/+fM/E1JfRsP/UchRVUtPHVHNvcvmujrkkRE5CwKswEcrGjir36yhQ6Xh1f/Zj6LpyT7uiQREelDYXYRx2ta+cLLHzFrXDxP3pZNVkqMr0sSEZF+KMwuoLGtiwf/YxseC0/dMYsJidG+LklERC5AYdaPLreHR1/bwam6Nn7+t1cpyEREHE5h1oe1lu/9zz4+OFLDc/fkcFVmoq9LEhGRAWhueR+v/uU4v9hykkc+PZl78zJ8XY6IiHhBYXaWjYeq+MHa/SzLHsM/3jzN1+WIiIiXFGY9Tne6yX+/mIWZifzL53IJCdEdoEVE/IXCrMfr206yubiWr900VbduERHxMwozoMPlJv9PxSyYmMCCSQm+LkdERC6Rwgz4zY5SyhvbeXRJlq9LERGRyxD0YeZye3hp01Fy0uO5bkqSr8sREZHLEPRhtnZ3OSfr2nj0hix6bjkjIiJ+JqjDzOOx/N+NR5g6JoalM8b4uhwREblMQR1m7+yvoKiqhUdvyNJUfBERPxa0YWat5cWNR5iYGMVtOWm+LkdERK5A0IbZzpMNHK5s4ZFPTyZUvTIREb8WtGFWsKuMqBGh3DF7nK9LERGRKxS0Ybb1WB3Z4+IYGR7q61JEROQKBWWYNbV3caCiifkTtdqHiEggCMow236iHmtRmImIBIigDLPC43WEhRjmjB/l61JERGQQOC7MjDHfM8aUGmN29jxW9Nduw4YNTJs2jaysLJ5++ulL+h3bjtWTPS5eq+OLiAQIx4VZj3+x1ub2PNb13eh2u3n00UdZv349+/fv55e//CX79+/3ascdLjc7SxqYP2H0oBctIiK+4dQwu6itW7eSlZVFZmYm4eHhrFq1ioKCAq/eu7ukkU6Xh/m61YuISMBwaph9xRiz2xjzM2PMeV2o0tJSMjIyep+np6dTWlrq1Y63Ha8DIE89MxGRgOGTMDPGvGuM2dvP4w7gJWAykAuUAz/q+35rbX/77Pd35efnk5eXR15eHtXV1dS2dHLTjBQSYyIG8yOJiIgP+WQGhLX2Jm/aGWNeBtb2fT09PZ1Tp071Pi8pKSEtrf/1FVevXs3q1asByMvL46PiWlJiFWQiIoHEccOMxpjUs57eBezt22b+/PkUFRVx7NgxOjs7ef3111m5cqVX+y9tOM240ZGDVK2IiDiB48IMeNYYs8cYsxu4Afh7gLKyMlas6J6lHxYWxosvvsiyZcuYMWMGn/3sZ8nOzh5wxx5raWjrYtyoqKGsX0REhpnp7/yTQ11xobNmz6Xllh/wb/fNYeVs3fZFRMSHBvV2JU7smQ2ZLrcbgHGjNMwoIhJIgirMOt3dnbt0nTMTEQkoQRVmXS4P4aEhJGtavohIQAmqMAO4floSIbqztIhIQAmqMGvvclPV1OHrMkREZJAFVZi5rSUucoSvyxARkUEWXGHmscSNVJiJiASa4AuzSN3DTEQk0ARfmKlnJiIScIImzNq73FggdqR6ZiIigSZowqy53QWgCSAiIgEoaMKsqb0LQMOMIiIBKHjC7HRPmGkCiIhIwAmaMDvd6WZEaAgxEQozEZFAEzRh1u5y0+X2EB4W6utSRERkkAVNmHV0eQCICAuajywiEjSC5pu9090dZuEKMxGRgBM03+zqmYmIBK6g+WbvUM9MRCRgBc03e0eXG4AITQAREQk4QRNmZ86ZaZhRRCTwBM03+5lzZuGhQfORRUSCRtB8s3e6PRggJMT4uhQRERlkQRNm1kKYemUiIgHJcWs7GWN+BUzreToKaLDW5vZtN3HiRGJjYwkNDSUsLIzCwsKL7re9y43bYwe7XBERcQDHhZm19nNnfjbG/AhovFDbjRs3kpSU5NV+PdZiNMIoIhKQHBdmZxhjDPBZYMlg7M/lsSjLREQCk5NPIi0GKq21Rf1tNMZw8803M2/ePPLz8y+4k/z8fPLy8vjv3/wWj8czVLWKiIgPGWuH/zySMeZdYGw/m75trS3oafMScMRa+6OebecUWlZWRlpaGlVVVSxdupQXXniB66677oK/8xtv7GLN33+WlpJDg/QpRETkCgzqYJlPhhmttTddbLsxJgz4DDDvQm3S0tIASElJ4a677mLr1q0XDTO3hhlFRAKWU4cZbwIOWmtL+tvY2tpKc3Nz78/vvPMOs2bNuugOXR47yP8fICIiTuHUMFsF/PLsF8rKylixYgUAlZWVXHvttcyePZsFCxZw6623snz58ovu0KOemYhIwPLJObPLdEWFfv3XO3nlH++j7sSBwapHREQu36D2L5zaMxt0ze0uXTQtIhKggibMPBadMxMRCVBBE2Z+NJwqIiKXKHjCDHXMREQCVdCEmUc9MxGRgBVEYebrCkREZKgETZhZrZovIhKwgijMfF2BiIgMlaAJs5S4CMJ1p2kRkYAUNN/u5Q3tdLl1CxgRkUAUNGFmNTlfRCRgBU+Y6ZyZiEjACp4w83UBIiIyZIImzJRmIiKBK2jCzCrNREQCVvCEmUUXTYuIBKjgCTNfFyAiIkMmaMLs01OTiYkI83UZIiIyBIImzL564xSSYyN8XYaIiAyBoAkzEREJXAozERHxewozERHxewozERHxewozERHxez4JM2PMvcaYfcYYjzEmr8+2bxljjhhjDhljlvX3/rq6OpYuXcqUKVNYunQp9fX1w1O4iIg4kq96ZnuBzwB/OvtFY8xMYBWQDSwHfmyMCe375qeffpobb7yRoqIibrzxRp5++unhqFlERBzKJ2FmrT1grT3Uz6Y7gNettR3W2mPAEWBB30YFBQU88MADADzwwAP87ne/G8pyRUTE4Zx2zmwccOqs5yU9r52jsrKS1NRUAFJTU6mqqrrgDvPz88nLyyMvL4/q6upBLldERJxgyNZ3Msa8C4ztZ9O3rbUFF3pbP69d0bKKq1evZvXq1QDk5eUN0FpERPzRkIWZtfamy3hbCZBx1vN0oKxvozFjxlBeXk5qairl5eWkpKRcbpkiIhIAjLW+W0/eGLMJ+Ia1trDneTbwGt3nydKAPwJTrLXuPu97Dqi11j5tjHkCSLDWftOL37fBWrt8kD+GiIj4mE/CzBhzF/ACkAw0ADuttct6tn0beBBwAV+z1q7vef0nwBprbaExJhH4NTAeOAnca62tG/YPIiIijuDTnpmIiMhgcNpsRhERkUumMBMREb+nMBMREb+nMBMREb+nMBMREb+nMBMREb+nMBMREb/3/wDK9eAZRiJ79QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sympy.plotting.plot.Plot at 0x7f2bd636a310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sympy.plotting.plot(sympy.log(theta/(1-theta)), (theta, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.6**\n",
    "MLE for Poisson distribution\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}|\\lambda) = \\frac{\\lambda^{\\sum {x_i}} \\exp(-\\lambda N)}{\\prod_i x_i!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\sum x_i = a$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}\\lambda} P(\\mathbf{x}|\\lambda) &= 0 \\\\\n",
    "a \\lambda^{a-1} \\exp(-\\lambda N) - N \\lambda^a \\exp(-\\lambda N) &= 0 \\\\\n",
    "a - N \\lambda &= 0 \\\\\n",
    "\\lambda &= \\frac{\\sum x_i}{N}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.7** Bayesian analysis for Poisson\n",
    "\n",
    "Conjugate prior is \n",
    "$$\n",
    "p(\\lambda) = \\frac{b^{a-1}}{\\Gamma(a)} \\lambda^{a-1} \\exp(-\\lambda b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson is Gamma distribution with $b=1$ and $a = k + 1$. So\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{Gamma}(\\sum x_i+1, N)\\mathrm{Gamma}(a,b) &= \\frac{b^{a-1}}{\\Gamma(a)\\Gamma(k+1)} \\lambda^{k+a-1} \\exp[-\\lambda(b+1)] \\\\\n",
    "                                          &\\propto \\mathrm{Gamma}(\\sum x_i+a, N+b)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $a=b=0$ we recover the maximum-likelihood estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.8** MLE for uniform distribution\n",
    "\n",
    "Uniform distribution for interval $[-a, a]$,\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}|a) = \\frac{1}{2 a} \\prod_i \\chi_{x_i \\in [-a,a]} = \\frac{1}{2 a} \\chi_{\\min_{x_i}\\ge -a} \\chi_{\\max_{x_i} \\le a} = \\frac{1}{2a} \\theta(\\min x_i + a) \\theta(a - \\max x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sympy.symbols(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sympy.plotting.plot.Plot at 0x7f2bd5fcc730>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sympy.plotting.plot(1/(2*a) * sympy.Heaviside(-3+a) * sympy.Heaviside(a-5), (a,1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{a} = \\max |x_i|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.9**\n",
    "\n",
    "Pareto prior and uniform distribution. Joint distribution is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathcal{D}, \\theta) &= \\left(\\frac{\\mathbb{I}_{0 \\le x_i \\le \\theta}}{\\theta}\\right)^N K b^K \\theta^{-(K+1)} \\mathbb{I}_{\\theta \\ge K} \\\\\n",
    "                       &= \\frac{K b^K}{\\theta^{N + K + 1}} \\mathbb{I}(\\theta \\ge \\max \\mathcal{D}) \\mathbb{I}(\\theta \\ge b)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence: (TODO: add this to card!)\n",
    "\n",
    "Let $m=\\max(\\mathcal{D})$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathcal{D}) &= \\int_{\\max(m, b)}^\\infty \\frac{K b^K}{\\theta^{N+k+1}}\\ \\mathrm{d}\\theta \\\\\n",
    "               &= K b^k \\left.\\frac{-1}{N+k} \\frac{1}{\\theta^{N+k}} \\right|_{\\max(m,b)}^\\infty \\\\\n",
    "               &= \\frac{K b^K}{N+k} \\frac{1}{\\max(m,b)^{N+k}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior distribution:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\theta|\\mathcal{D}) &= \\frac{p(\\mathcal{D},\\theta)}{p(\\mathcal{D})} \\\\\n",
    "                      &= \\frac{(N+k) \\max(m,b)^{N+k}}{\\theta^{N+K+1}} \\mathbb{I}(\\theta \\ge m) \\mathbb{I}(\\theta \\ge b) \\\\\n",
    "                      &= \\frac{(N+k) \\max(m,b)^{N+k}}{\\theta^{N+K+1}} \\mathbb{I}[\\theta \\ge \\max(m, b)]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So $p(\\theta|\\mathcal{D}) \\sim \\mathrm{Pareto}(N+k, \\max(m,b))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.10**\n",
    "a. Uniformative prior $p(\\theta|\\mathcal{D}) = A/\\theta$.\n",
    "Joint probability:\n",
    "\n",
    "$$\n",
    "P(\\theta, \\mathcal{D}) = \\frac{m}{\\theta^{N+1}} \\mathbb{I}(\\theta \\ge m)\n",
    "$$\n",
    "\n",
    "Evidence:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\mathcal{D}) &= \\int_m^\\infty \\frac{m}{\\theta^{N+1}}\\ \\mathrm{d}\\theta \\\\\n",
    "               &= \\frac{m}{N m^N}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So posterior is $$P(\\theta|\\mathcal{D}) = \\frac{N m^N}{\\theta^{N+1}} \\mathbb{I}(\\theta \\ge m) \\sim \\mathrm{Pareto}(N, m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive number of next cab:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x|\\mathcal{D}) &= \\int_m^\\infty P(x|\\theta) P(\\theta|\\mathcal{D})\\ \\mathrm{d}\\theta \\\\\n",
    "                 &= N m^N \\int_m^\\infty \\theta^{-(N+2)}\\ \\mathrm{d}\\theta \\\\\n",
    "                 &= N m^N \\left. -\\frac{1}{N+1} \\theta^{-(N+1)}\\right|_m^\\infty \\\\\n",
    "                 &= \\frac{N m^N}{N+1} \\frac{1}{m^{N+1}} \\\\\n",
    "                 &= \\frac{N}{m(N+1)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.13**\n",
    "Posterior predictive distribution for a batch of data with the dirichlet-multinomial model\n",
    "In Equation 3.51, we gave the the posterior predictive distribution for a single multinomial trial using a\n",
    "dirichlet prior. Now consider predicting a batch of new data, $\\tilde{\\mathcal{D}} = (X_1,\\ldots, X_s)$, consisting of $s$ single\n",
    "multinomial trials (think of predicting the next $m$ words in a sentence, assuming they are drawn iid).\n",
    "Derive an expression for $p(\\tilde{\\mathcal{D}}|\\mathcal{D},\\alpha)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial distribution. State space for individual sample point is $\\{1, \\ldots, m\\}$, each with a probability $\\theta_1, \\ldots, \\theta_m$.\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}|\\mathbf{\\theta}) = {N \\choose k_1 \\cdots k_m} \\theta_1^{k_1} \\cdots \\theta_m^{k_m}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior distribution is Dirichlet, which is the continuous extension of the multinomial distribution:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{\\theta}|\\mathbf{\\alpha}) = \\frac{\\Gamma(\\alpha_1 + \\cdots + \\alpha_m)}{\\Gamma(\\alpha_1)\\cdots\\Gamma(\\alpha_m)} \\theta_1^{\\alpha_1-1} \\cdots \\theta_m^{\\alpha_m-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior given the data is also Dirichlet,\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{\\theta}|\\mathcal{D}) \\sim \\mathrm{Dirichlet}(\\alpha_1+k_1, \\ldots, \\alpha_m+k_m)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior-predictive is then\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\tilde{D}'|\\mathcal{D}, \\boldsymbol{\\alpha}) &= \\int p(\\tilde{D}'|\\boldsymbol{\\theta}) p(\\boldsymbol{\\theta}|\\boldsymbol{\\alpha})\\ \\mathrm{d}\\boldsymbol{\\theta} \\\\\n",
    "&= {N' \\choose k_1' \\cdots k_m'} \\frac{\\Gamma(\\alpha_1 + k_1 + \\cdots + \\alpha_m + k_m)}{\\Gamma(\\alpha_1+k_1)\\cdots\\Gamma(\\alpha_m+k_m)} \\int \\theta_1^{\\alpha_1 + k_1 + k_1'  - 1}\\ \\mathrm{d}\\theta_1 \\cdots \\int \\theta_m^{\\alpha_m + k_m+k_m'- 1}\\ \\mathrm{d}\\theta_m \\\\\n",
    "&= {N' \\choose k_1' \\cdots k_m'} \\frac{\\Gamma(\\alpha_1 + k_1 + \\cdots + \\alpha_m + k_m)}{\\Gamma(\\alpha_1+k_1)\\cdots\\Gamma(\\alpha_m+k_m)} \\frac{\\Gamma(\\alpha_1 + k_1 + k_1') \\cdots \\Gamma(\\alpha_m + k_m + k_m')}{\\Gamma(\\alpha_1 + k_1 + k_1' + \\cdots \\alpha_m + k_m + k_m')} \\\\\n",
    "&= \\frac{\\Gamma(k_1'+\\cdots+k_m'+1)}{\\Gamma(k_1'+1)\\cdots\\Gamma(k_m'+1)} \\frac{\\Gamma(\\alpha_1 + k_1 + \\cdots + \\alpha_m + k_m)}{\\Gamma(\\alpha_1+k_1)\\cdots\\Gamma(\\alpha_m+k_m)} \\frac{\\Gamma(\\alpha_1 + k_1 + k_1') \\cdots \\Gamma(\\alpha_m + k_m + k_m')}{\\Gamma(\\alpha_1 + k_1 + k_1' + \\cdots \\alpha_m + k_m + k_m')}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where the second equality comes from the fact that the integral over the domain of the Dirichlet distribution is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.14**\n",
    "\n",
    "a) $m=27$, $\\sum k_i = 2000$, $k_e=260$. $\\alpha_k=10$, $\\sum \\alpha_i = 270$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_{2001}=a|\\mathcal{D}, \\boldsymbol{\\alpha}) &= \\frac{\\Gamma(2)}{\\Gamma(2)} \\frac{\\Gamma(\\sum \\alpha_i + \\sum k_i)}{\\Gamma(10+260) \\Gamma(\\alpha_1 + k_1) \\cdots \\Gamma(\\alpha_m+k_m)} \\frac{\\Gamma(\\alpha_1+k_1) \\cdots \\Gamma(10+260+1) \\cdots \\Gamma(\\alpha_m+k_m)}{\\Gamma(\\sum \\alpha_i + \\sum k_i + 1)} \\\\\n",
    "&= \\frac{\\Gamma(2270)}{\\Gamma(10+260)}\\frac{\\Gamma(10+260+1)}{\\Gamma(2271)} \\\\\n",
    "&= \\frac{(2270-1)!}{(10+260-1)!}\\frac{(10+260)!}{(2270)!} \\\\\n",
    "&= \\frac{270}{2270} \\\\\n",
    "&= 0.1189\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, numpy.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = numpy.ones(27)*10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = numpy.ones(27)*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[0]=260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[1]=k[1]+(2000-numpy.sum(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = numpy.random.dirichlet(alpha+k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = numpy.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = rng.multinomial(1, theta[0], size=nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2, ..., 9997, 9998, 9999]),\n",
       " array([ 9, 25,  1, ..., 17, 10,  1]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.where(samples[:] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.shape(numpy.where(numpy.where(samples == 1)[1] == 0))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "\n",
    "for i in range(1000):\n",
    "    theta = numpy.random.dirichlet(alpha+k, 1)\n",
    "    samples = rng.multinomial(1, theta[0], size=nsamples)\n",
    "    c += numpy.shape(numpy.where(numpy.where(samples == 1)[1] == 0))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11901210000000001"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c/nsamples/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.16**\n",
    "Write a program to solve for $(\\alpha_1, \\alpha_2)$ of a Beta distribution given that $E \\theta = m$ and $p(l < \\theta < u) = p_0$.\n",
    "\n",
    "$$\n",
    "\\mathrm{Beta}(\\theta|\\alpha_1, \\alpha_2) = \\frac{\\Gamma(\\alpha_1 + \\alpha_2)}{\\Gamma(\\alpha_1) \\Gamma(\\alpha_2)} \\theta^{\\alpha_1-1} (1-\\theta)^{\\alpha_2 - 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E \\theta = \\frac{\\alpha_1}{\\alpha_1 + \\alpha_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, a1, a2, p0, p1 = sympy.symbols(\"x alpha1 alpha2 p0 p1\", Reals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.integrate(x**(a1-1)*(1-x)**(a2-1), (x, p0, p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.17** Marginal likelihood for beta-binomial under uniform prior\n",
    "Suppose we toss a coin $N$ times and observe $N_1$ heads. Let $N_1 \\sim \\mathrm{Bin}(N_1, \\theta)$ and $\\theta \\sim \\mathrm{Beta}(1,1)$. Show that the marginal likelihood is $p(N_1|N) = 1/(N +1)$. Hint: $\\Gamma(x + 1) = x!$ if $x$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal likelihood\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(N_1|N) &= \\int p(N_1|N,\\theta) p(\\theta)\\ \\mathrm{d}\\theta\\\\\n",
    "         &= {N \\choose N_1} \\int \\theta^{N_1} (1-\\theta)^{N-N_1} \\frac{\\Gamma(2)}{\\Gamma(1)\\Gamma(1)}\\ \\mathrm{d}\\theta \\\\\n",
    "         &= {N \\choose N_1} \\frac{\\Gamma(2)}{\\Gamma(1)\\Gamma(1)} \\int \\theta^{N_1+1-1} (1-\\theta)^{N+1-N_1-1}\\ \\mathrm{d}\\theta \\\\\n",
    "         &= {N \\choose N_1} \\frac{\\Gamma(2)}{\\Gamma(1)\\Gamma(1)} \\frac{\\Gamma(N_1+1)\\Gamma(N+1-N_1)}{\\Gamma(N_1+1 + N + 1 - N_1)} \\\\\n",
    "         &= \\frac{\\Gamma(N+1)}{\\Gamma(N_1+1) \\Gamma(N-N_1+1)} \\frac{\\Gamma(N_1+1)\\Gamma(N+1-N_1)}{\\Gamma(N + 2)} \\\\\n",
    "         &= \\frac{\\Gamma(N+1)}{\\Gamma(N+2)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.18** Bayes factor for coin tossing\n",
    "Suppose we toss a coin $N = 10$ times and observe $N_1 = 9$ heads. Let the null hypothesis be that the\n",
    "coin is fair, and the alternative be that the coin can have any bias, so $p(\\theta) = \\mathrm{Unif} (0,1)$. Derive the\n",
    "Bayes factor $BF_{1,0}$ in favor of the biased coin hypothesis. What if $N = 100$ and $N_1 = 90$? Hint: see\n",
    "Exercise 3.17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{BF}_{0,1} &= \\frac{P(\\mathcal{D}|M_0)}{P(\\mathcal{D}|M_1)} \\\\\n",
    "                  &= \\frac{\\int P(N_1|N, \\theta) \\delta(\\theta-1/2)\\ \\mathrm{d}\\theta}{\\int P(N_1|N, \\theta) \\mathrm{Uni}(0,1)\\ \\mathrm{d}\\theta} \\\\\n",
    "                  &= {N \\choose N_1} \\frac{1}{2}^N \\frac{1}{N+1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008877840909090909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.special.comb(10,9) * 0.5**10/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3520224146003067e-19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.special.comb(100,90) * 0.5**100/101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.19**\n",
    "\n",
    "a. $p(C=1)=p(C=2)=0.5$. Log posterior odds ratio\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log \\frac{P(C=1|\\mathbf{x}_i)}{P(C=2|\\mathbf{x}_i)} &= \\log \\frac{P(\\mathbf{x}_i|C=1) P(C=1)}{P(\\mathbf{x}_i|C=2) P(C=2)} \\\\\n",
    "    &= \\log P(\\mathbf{x}_i|C=1) - P(\\mathbf{x}_i|C=2) \\\\\n",
    "    &= \\phi(\\mathbf{x}_i)^T \\left(\\boldsymbol{\\beta}_1 - \\boldsymbol{\\beta}_2\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the condition that individual words to not change the odds ratio?\n",
    "\n",
    "$$\n",
    "\\log \\frac{\\theta_{1,j}}{1-\\theta_{1,j}} = \\log \\frac{\\theta_{2,j}}{1-\\theta_{2,j}}\n",
    "$$\n",
    "\n",
    "where $\\theta_{c,j}$ is the probability that word $j$ appears in documents of class $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{cw} = \\frac{1+\\sum_i x_{iw}}{2 + n_c}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plug that into the condition (b) we get\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log \\frac{1+\\sum_i x_{iw}}{2+n_c} \\left(1-\\frac{1+\\sum_i x_{iw}}{2+n_c}\\right)^{-1}\n",
    "  &= \\log \\frac{1+\\sum_i x_{iw}}{2+n_c} \\left(\\frac{2+n_c - 1+\\sum_i x_{iw}}{2+n_c}\\right)^{-1} \\\\\n",
    "  &= \\log \\frac{1+\\sum_i x_{iw}}{2+n_c} \\frac{2+n_c}{1+n_c +\\sum_i x_{iw}} \\\\\n",
    "  &= \\log \\frac{1+\\sum_i x_{iw}}{1+n_c +\\sum_i x_{iw}} \\\\\n",
    "  &= \\log \\left(1+\\sum_i x_{iw}\\right) - \\log \\left(1+n_c +\\sum_i x_{iw}\\right) \\\\\n",
    "  &= \\log \\left(1+n_c \\right) - \\log \\left(1+n_c + n_c\\right) \\\\\n",
    "  &= \\log \\left(1+n_c \\right) - \\log \\left(1+2 n_c\\right) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where the second to last equality comes from the fact that the word occurs in all documents, regardless of the class. So the answer is no, the word does not get disregarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.20**\n",
    "\n",
    "a. $D$-variate Bernoulli:\n",
    "\n",
    "$$\n",
    "p(x_1, \\ldots, x_d) = \\theta_{1\\cdots}^{x_1 \\cdots} \\theta_{0\\cdots}^{(1-x_1) \\cdots} \\cdots \\theta_{\\cdots 1\\cdots}^{\\cdots x_i \\cdots} \\theta_{\\cdots 0 \\cdots}^{\\cdots (1-x_i) \\cdots} \n",
    "$$\n",
    "\n",
    "This has $2^d - 1$ parameters, which means that the total number of parameters is $C (2^d-1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. + c. I would assume for low $N$ it is better to use the naive model since otherwise we have more parameters than samples. For large $N$, the full model seems to be better unless we know a priori that the probabilities are independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. We assume that we have the feature vector $\\mathbf{x}_i$ for each document already, i.e. we don't need to go through the words of the individual document (otherwise just multiply all costs by $\\sum D_i$ where $D_i$ is the number of words in each document).\n",
    "\n",
    "Then for naive Bayes MLE we have $\\mathcal{O}(N D)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
