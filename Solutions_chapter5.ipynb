{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.**\n",
    "Mixture of conjugate priors\n",
    "\n",
    "$$\n",
    "\\pi(\\theta) = \\sum_k p_k \\pi_k(\\theta)\n",
    "$$\n",
    "\n",
    "Show that \n",
    "$$\n",
    "p(\\theta|\\boldsymbol{x}) = \\sum_k P(z=k|\\boldsymbol{x}) P(\\theta|\\boldsymbol{x},k) = \\sum_k P(z=k|\\boldsymbol{x}) \\frac{P(\\boldsymbol{x}|\\theta) \\pi_k(\\theta)}{\\int P(\\boldsymbol{x}|\\theta) \\pi_k(\\theta)}\n",
    "$$\n",
    "\n",
    "Where $Z$ picks the prior distribution from the mixture.\n",
    "\n",
    "$$\n",
    "P(z=k|\\boldsymbol{x}) = \\frac{P(\\boldsymbol{x}|z=k) p_k}{\\sum_{k'} P(\\boldsymbol{x}|z=k') p_{k'}}\n",
    "$$\n",
    "\n",
    "and $P(\\boldsymbol{x}|z=k)$ is the marginal likelihood (evidence) for the mixture component $k$, i.e. \n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{x}|z=k) = \\int P(\\boldsymbol{x}|\\theta) \\pi_k(\\theta)\\ \\mathrm{d}\\theta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then \n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\theta|\\boldsymbol{x}) &= \\frac{p(\\boldsymbol{x}|\\theta) \\pi(\\theta)}{\\int p(\\boldsymbol{x}|\\theta) \\pi(\\theta)} \\\\\n",
    "&= \\frac{p(\\boldsymbol{x}|\\theta) \\sum_k p_k \\pi_k(\\theta)}{\\int p(\\boldsymbol{x}|\\theta) \\sum_k p_k \\pi_k(\\theta)} \\\\\n",
    "&= \\frac{p(\\boldsymbol{x}|\\theta) \\sum_k p_k \\pi_k(\\theta)}{\\sum_{k'} P(\\boldsymbol{x}|z=k) p_{k'}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2. Optimal threshold**\n",
    "We have a posterior distribution $P(y|\\boldsymbol{x})$ and two classes such that $p_0 = P(y=0|\\boldsymbol{x})$ and $p_1 = P(y=1|\\boldsymbol{x})$. Consider loss matrix such that $l(y=0, \\hat{y}=1) = \\lambda_{10}$ and $l(y=1, \\hat{y}=0) = \\lambda_{01}$.\n",
    "\n",
    "a. Minimize expected loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E} l = p_0 \\lambda_{10} \\hat{y} + p_1 \\lambda_{01} (1-\\hat{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should pick $\\hat{y}=1$ if $p_1 \\lambda_{01} \\ge p_0 \\lambda_{10}$. So\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p_1 \\lambda_{01} & \\ge p_0 \\lambda_{10} \\\\\n",
    "p_1 \\lambda_{01} & \\ge (1-p_1) \\lambda_{10} \\\\\n",
    "p_1 \\lambda_{01} & \\ge \\lambda_{10} - p_1 \\lambda_{10} \\\\\n",
    "p_1 (\\lambda_{01} + \\lambda_{10}) &\\ge \\lambda_{10} \\\\\n",
    "p_1 &\\ge \\frac{\\lambda_{10}}{\\lambda_{01} + \\lambda_{10}}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Threshold should be 0.1. Easy, e.g. $\\lambda_{10}=1$ and $\\lambda_{01} = 9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3. Reject option**\n",
    "Let the loss function be defined as\n",
    "\n",
    "$$\n",
    "l(\\alpha_i|Y_j) = \\begin{cases} 0 &, i=j \\wedge i,j \\le C \\\\ \\lambda_r &, i = C+1 \\\\ \\lambda_s &,\\ \\mathrm{else}\\end{cases},\n",
    "$$\n",
    "\n",
    "where $C$ is the number of classes and $C+1$ refers to the reject option. Let $p_j = P(Y=j|\\boldsymbol{x})$ be the posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize expected loss:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}l\n",
    "&= \\sum_j l(\\alpha_i|Y_j) p(Y_j) \\\\\n",
    "&= \\lambda_r \\delta_{i,C+1} + \\lambda_s \\sum_j (1-\\delta_{ij}) p_j \\\\\n",
    "&= \\lambda_r \\delta_{i,C+1} + \\lambda_s \\sum_j p_j - \\lambda_s p_i \\\\\n",
    "&= \\lambda_r \\alpha_{C+1} + \\lambda_s 1 - \\lambda_s p_j \\alpha_j \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take rejection, if\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\lambda_r \\le \\lambda_s (1 - \\max_j p_j)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "else take $\\mathrm{argmax} p_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4. More reject options**\n",
    "Loss matrix:\n",
    "\n",
    "$$\n",
    "\\lambda(\\alpha_i|y_j) = 3 \\alpha_2 + 10 \\alpha_1 y_0 + 10 \\alpha_0 y_1\n",
    "$$\n",
    "\n",
    "Expected loss:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E} l\n",
    "&= \\sum_j l(\\alpha_i|y_j) p_j \\\\\n",
    "&= 3 \\alpha_2 + 10 \\alpha_1 p_0 + 10 \\alpha_0 p_1 \\\\\n",
    "&= 3 \\alpha_2 + 10 \\alpha_1 (1-p_1) + 10 \\alpha_0 p_1 \\\\\n",
    "&= 3 \\alpha_2 + 10 \\alpha_1 - 10 \\alpha_1 p_1 + 10 \\alpha_0 p_1 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose $\\alpha_0$ if \n",
    "$$\n",
    "\\begin{align}\n",
    "p_1 &\\le \\min(0.3, 1-p_1) \\\\\n",
    "p_1 &\\le 0.3\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Choose $\\alpha_1$ if $p_1 > 0.3$ and\n",
    "$$\n",
    "\\begin{align}\n",
    "10 (1-p_1) &\\le 3 \\\\\n",
    "10 - 3 &\\le 10 p_1 \\\\\n",
    "p_1 &\\ge 0.7\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Else reject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.5**\n",
    "Quantity $Q$, demand $D$ with probability $f(D)$. Cost is $C$, selling price is $P$. Then the expected profit if we buy quantity $Q$ is\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\pi(Q) = - C Q + \\int_0^Q P D f(D)\\ \\mathrm{d}D + \\int_Q^\\infty P Q f(D)\\ \\mathrm{d}D\n",
    "$$\n",
    "\n",
    "The last term is because we can still sell $Q$ items even if the demand is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their expression is \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}\\pi(Q) \n",
    "&= \\int_Q^\\infty (P-C)Qf(D)\\ \\mathrm{d}D + \\int_0^Q (P-C) D f(D)\\ \\mathrm{d}D - \\int_0^Q C (Q-D) f(D)\\ \\mathrm{d}D\\\\\n",
    "&= P Q \\int_Q^\\infty f(D)\\ \\mathrm{d}D - C Q \\int_Q^\\infty f(D)\\ \\mathrm{d}D + P \\int_0^Q D f(D)\\ \\mathrm{d}D - C \\int_0^Q D f(D)\\ \\mathrm{d}D - C Q \\int_0^Q f(D)\\ \\mathrm{d}D + C \\int_0^Q D f(D)\\ \\mathrm{d}D \\\\\n",
    "&= - C Q + P Q \\int_Q^\\infty f(D)\\ \\mathrm{d}D + P \\int_0^Q D f(D)\\ \\mathrm{d}D \\\\\n",
    "&= - C Q + P Q [1-F(Q)] +  P \\int_0^Q D f(D)\\ \\mathrm{d}D\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leibnitz rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d} \\theta} \\int_{a(\\theta)}^{b(\\theta)} f(x)\\ \\mathrm{d}x = f[b(\\theta)] b'(\\theta) - f[a(\\theta)] a'(\\theta) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maximize the profit\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}Q} \\mathbb{E}\\pi(Q)\n",
    "&= -C + P - P F(Q) - P Q F'(q) + P \\frac{\\mathrm{d}}{\\mathrm{d}Q} \\int_0^Q D f(D)\\ \\mathrm{d}D \\\\\n",
    "&= -C + P - P F(Q) - P Q f(q) + P Q f(Q) \\\\\n",
    "&= -C + P - P F(Q)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.8 Biased coin flip with unreliable reporting**\n",
    "Probability head $\\theta_1$ with corresponding rv $x=\\{1,0\\}$. Probability of correct reporting $\\theta_2$ with corresponding RV $Y$.\n",
    "\n",
    "So \n",
    "\n",
    "$$\n",
    "\\begin{array}{rcc}\n",
    "RV & Y=0 & Y=1 \\\\\n",
    "X=0 & (1-\\theta_1) \\theta_2 & (1-\\theta_1) (1-\\theta_2) \\\\\n",
    "X=1 & \\theta_1 (1-\\theta_2) & \\theta_1 \\theta_2 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write that as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x,y|\\boldsymbol{\\theta}) \n",
    "&= (1-\\theta_1)^{(1-x)(1-y)} \\theta_2^{(1-x)(1-y)} (1-\\theta_1)^{(1-x)y} (1-\\theta_2)^{(1-x)y} \\theta_1^{x(1-y)} (1-\\theta_2)^{x(1-y)} \\theta_1^{xy}\\theta_2^{xy} \\\\\n",
    "&= p(y|x, \\theta_2) p(x|\\theta_1) \\\\\n",
    "&= \\left[\\theta_2^{(1-x)(1-y)} (1-\\theta_2)^{(1-x)y} (1-\\theta_2)^{x(1-y)} \\theta_2^{xy}\\right]\\left[(1-\\theta_1)^{(1-x)} \\theta_1^{x}\\right] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.array([[1,1,0,1,1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = numpy.array([[1,0,0,0,1,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = numpy.vstack((x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample probability:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log p(\\boldsymbol{x}, \\boldsymbol{y}|\\boldsymbol{\\theta}) &=\n",
    "\\sum_i \\log p(y_i|x_i, \\theta_2) p(x_i|\\theta_1) \\\\\n",
    "&= \\sum_i \\left[\\log p(y_i|x_i, \\theta_2) + \\log p(x_i|\\theta_1)\\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimizing the second term means minimizing a sum of Bernoulli trials:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}\\theta_1} \\sum_i \\log p(x_i|\\theta_1)\n",
    "&= \\frac{\\mathrm{d}}{\\mathrm{d}\\theta_1}\\sum_i \\log (1-\\theta_1)^{(1-x_i)} \\theta_1^{x_i} \\\\\n",
    "&= \\frac{\\mathrm{d}}{\\mathrm{d}\\theta_1}\\sum_i (1-x_i) \\log (1-\\theta_1) + x_i \\log \\theta_1 \\\\\n",
    "&= \\sum_i \\frac{1-x_i}{1-\\theta_1} + \\frac{x_i}{\\theta_1} \\\\\n",
    "&= \\frac{N_-}{1-\\theta_1} + \\frac{N_+}{\\theta_1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So\n",
    "$$\n",
    "\\begin{align}\n",
    "N_+ (1- \\hat{\\theta}_1) - (N-N_+) \\hat{\\theta}_1 &= 0 \\\\\n",
    "N_+ - N_+ \\hat{\\theta}_1 - N \\hat{\\theta}_1 + N_+ \\hat{\\theta}_1 &= 0 \\\\\n",
    "\\hat{\\theta}_1  N &= -N_+ \\\\\n",
    "\\hat{\\theta}_1 = \\frac{N_+}{N}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = numpy.sum(x)/x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can minimize the first part:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}\\theta_2} \\sum_i \\log p(y_i|x_i, \\theta_2) &=\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}\\theta_2} \\sum_i \\log \\theta_2^{(1-x)(1-y)} (1-\\theta_2)^{(1-x)y} (1-\\theta_2)^{x(1-y)} \\theta_2^{xy} \\\\\n",
    "&= \\sum_i \\frac{(1-x)(1-y)}{\\theta_2} + \\frac{(1-x)y}{1-\\theta_2} + \\frac{x(1-y)}{1-\\theta_2} + \\frac{xy}{\\theta_2} \\\\\n",
    "&= \\frac{N_{--}}{\\theta_2} + \\frac{N_{-+}}{1-\\theta_2} + \\frac{N_{+-}}{1-\\theta_2} + \\frac{N_{++}}{\\theta_2} \\\\\n",
    "&= \\frac{N_\\mathrm{correct}}{\\theta_2} + \\frac{N_\\mathrm{incorrect}}{1-\\theta_2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $N_\\mathrm{correct}$ denotes the number of correctly reported samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncorrect = numpy.sum(s.sum(0) % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2 = ncorrect/x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5714285714285714, 0.5714285714285714)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\mathcal{D}|\\hat{\\boldsymbol{\\theta}})$ is just the joint sample probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npp = numpy.sum(numpy.logical_and(s[0,:] == 1, s[1,:] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmm = numpy.sum(numpy.logical_and(s[0,:] == 0, s[1,:] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Npm = numpy.sum(numpy.logical_and(s[0,:] == 1, s[1,:] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmp = numpy.sum(numpy.logical_and(s[0,:] == 0, s[1,:] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.044252239799105e-05"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1-theta1)*theta2)**Nmm * ((1-theta1)*(1-theta1))**Nmp * (theta1*(1-theta2))**Npm * (theta1*theta2)**Npp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, three parameter model with $\\boldsymbol{\\theta}=(\\theta_{0,0},\\theta_{0,1},\\theta_{1,0}, 1-\\theta_{0,0} + \\theta_{0,1} + \\theta_{1,0})$.\n",
    "\n",
    "Sample probability is\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D}|\\boldsymbol{\\theta}) = \\theta_{0,0}^{N_{00}} \\theta_{0,1}^{N_{01}} \\theta_{1,0}^{N_{10}} (1-\\theta_{0,0} - \\theta_{0,1} - \\theta_{1,0})^{N_{11}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log likelihood:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log P(\\mathcal{D}|\\boldsymbol{\\theta}) = {N_{00}} \\log \\theta_{0,0} + {N_{01}} \\log \\theta_{0,1} + {N_{10}} \\log \\theta_{1,0} +  {N_{11}} \\log (1-\\theta_{0,0} - \\theta_{0,1} - \\theta_{1,0})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n00, n01, n10, n11, theta00, theta01, theta10 = sympy.symbols(\"n00 n01 n10 n11 theta00 theta01 theta10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = n00 * sympy.log(theta00) + n10 * sympy.log(theta10) + n01 * sympy.log(theta01) + n11 *sympy.log(1-theta00-theta01-theta10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = [sympy.simplify(sympy.diff(p, theta00) * theta00 *(1-theta00-theta01-theta10)),\n",
    "      sympy.simplify(sympy.diff(p, theta01) * theta01 *(1-theta00-theta01-theta10)),\n",
    "      sympy.simplify(sympy.diff(p, theta10) * theta10 *(1-theta00-theta01-theta10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-n00*(theta00 + theta01 + theta10 - 1) - n11*theta00,\n",
       " -n01*(theta00 + theta01 + theta10 - 1) - n11*theta01,\n",
       " -n10*(theta00 + theta01 + theta10 - 1) - n11*theta10]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left\\{\\left( \\frac{n_{00}}{n_{00} + n_{01} + n_{10} + n_{11}}, \\  \\frac{n_{10}}{n_{00} + n_{01} + n_{10} + n_{11}}, \\  \\frac{n_{01}}{n_{00} + n_{01} + n_{10} + n_{11}}\\right)\\right\\}$"
      ],
      "text/plain": [
       "FiniteSet((n00/(n00 + n01 + n10 + n11), n10/(n00 + n01 + n10 + n11), n01/(n00 + n01 + n10 + n11)))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sympy.linsolve(ms, theta00, theta10, theta01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta00, theta01, theta10 = Nmm/(Nmm+Nmp+Npm+Npp), Nmp/(Nmm+Nmp+Npm+Npp), Npm/(Nmm+Nmp+Npm+Npp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta11 = 1 - theta00-theta01-theta10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2857142857142857,\n",
       " 0.14285714285714285,\n",
       " 0.2857142857142857,\n",
       " 0.2857142857142857)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta00, theta01, theta10, theta11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.771300344972876e-05"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta00**Nmm*theta10**Npm*theta01**Nmp*theta11**Npp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-one-out CV likelihood:\n",
    "\n",
    "$$\n",
    "L = \\sum_i \\log p[x_i,y_i|\\hat{\\boldsymbol{\\theta}}(\\mathcal{D}_{-1})]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For two parameter model:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\theta}_1 &= \\frac{N_+}{N} \\\\\n",
    "\\hat{\\theta}_2 &= \\frac{N_\\mathrm{correct}}{N}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(x,y|\\boldsymbol(\\theta)) \n",
    "= \\left[\\theta_2^{(1-x)(1-y)} (1-\\theta_2)^{(1-x)y} (1-\\theta_2)^{x(1-y)} \\theta_2^{xy}\\right]\\left[(1-\\theta_1)^{(1-x)} \\theta_1^{x}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $(0,0)$ we have\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_1(\\mathcal{D}_{-i}) = \\frac{N_- - 1}{N_1} = \\frac{N \\hat{\\theta}_1 - 1}{N-1}\n",
    "$$\n",
    "\n",
    "and \n",
    "$$\n",
    "\\hat{\\theta}_2(\\mathcal{D}_{-i}) = \\frac{N_\\mathrm{correct}-1}{N-1} = \\frac{N \\hat{\\theta}_2 - 1}{N-1} = \\frac{N}{N-1}\\hat{\\theta}_2 - \\frac{1}{N-1}\n",
    "$$.\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x_i=0,y_i=0|\\boldsymbol{\\hat{\\theta}}(\\mathcal{D}_{-i})) \n",
    "&= \\frac{N(1-\\hat{\\theta}_1)}{N-1} \\frac{N \\hat{\\theta}_2 - 1}{N-1} \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $x_i=1$ we have \n",
    "$$\n",
    "\\hat{\\theta}_1(\\mathcal{D}_{-i}) = \\frac{N_+-1}{N-1} = \\frac{N \\hat{\\theta}_1 - 1}{N-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x_i=1,y_i=0|\\boldsymbol{\\hat{\\theta}}(\\mathcal{D}_{-i})) \n",
    "&= \\frac{N \\hat{\\theta}_1 - 1}{N-1} \\frac{N(1-\\hat{\\theta}_2)}{N-1} \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x_i=1,y_i=1|\\boldsymbol{\\hat{\\theta}}(\\mathcal{D}_{-i})) \n",
    "&= \\frac{N \\hat{\\theta}_1 - 1}{N-1} \\frac{N \\hat{\\theta}_2 - 1}{N-1} \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x_i=0,y_i=1|\\boldsymbol{\\hat{\\theta}}(\\mathcal{D}_{-i})) \n",
    "&= \\frac{N(1-\\hat{\\theta}_1)}{N-1}  \\frac{N \\hat{\\theta}_1 - 1}{N-1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L &= N_{--} \\left[\\log[N(1-\\hat{\\theta}_1)] + \\log[N\\hat{\\theta}_2 - 1]\\right] \\\\\n",
    "  &+ N_{+-} \\left[\\log[N\\hat{\\theta}_1 -1] + \\log [N(1-\\hat{\\theta}_2)]\\right] \\\\\n",
    "  &+ N_{-+} \\left[\\log[N(1-\\hat{\\theta}_1)] + \\log[N\\hat{\\theta}_1 - 1]\\right] \\\\\n",
    "  &+ N_{++} \\left[\\log[N \\hat{\\theta}_1-1] + \\log[N \\hat{\\theta}_2 - 1]\\right] \\\\\n",
    "&- 2 N \\log(N-1)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four parameter model:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{xy} = \\frac{N_{xy}}{N}\n",
    "$$\n",
    "\n",
    "So \n",
    "$$\n",
    "\\hat{\\theta}_{x_i,y_i}(\\mathcal{D}_{-i}) = \\frac{N_{xy}-1}{N-1} = \\frac{N \\hat{\\theta}_{x_i,y_i} - 1}{N-1}\n",
    "$$\n",
    "and all other $\\hat{\\theta}$ are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L &= N_{--} \\left[\\log (N \\hat{\\theta}_{00}-1) - \\log(N-1)\\right] \\\\\n",
    "&+ N_{+-} \\left[\\log (N \\hat{\\theta}_{10}-1) - \\log(N-1)\\right] \\\\\n",
    "&+ N_{-+} \\left[\\log (N \\hat{\\theta}_{01}-1) - \\log(N-1)\\right] \\\\\n",
    "&+ N_{++} \\left[\\log (N \\hat{\\theta}_{11}-1) - \\log(N-1)\\right] \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-likelihood of full model is\n",
    "\n",
    "$$\n",
    "N_{--} \\log \\hat{\\theta}_{00} + N_{+-} \\log \\hat{\\theta}_{10} + N_{-+} \\log \\hat{\\theta}_{01} + N_{++} \\log \\hat{\\theta}_{11}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
